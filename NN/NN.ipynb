{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70457aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, f1_score\n",
    "from sklearn.metrics import \n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from itertools import product\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import random\n",
    "import openpyxl  \n",
    "from tensorflow.keras import layers, Sequential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ModeChoiceOptima.txt', sep=\"\\t\", header=None)\n",
    "\n",
    "# Renaming correctly the columns of pandas data\n",
    "columnsID = data.columns\n",
    "featureNames = data.iloc[0, :]\n",
    "NameDictionary = dict(zip(columnsID, featureNames))\n",
    "data.rename(columns = NameDictionary, inplace = True)\n",
    "data.drop(index=data.index[0], axis=0, inplace=True)\n",
    "\n",
    "data.drop((data[data.Choice == '-1']).index, inplace = True)\n",
    "data.drop((data[data.Choice == '-2']).index, inplace = True)\n",
    "data.drop((data[data.Choice == '2']).index, inplace = True)\n",
    "\n",
    "# Replacing all other '-1' and '-2' with NaN for consistency\n",
    "data.replace('-1', np.nan, inplace=True)\n",
    "data.replace('-2', np.nan, inplace=True)\n",
    "\n",
    "# Changing the dtype to numerical values, because it should help speed things up\n",
    "data = data.apply(pd.to_numeric, errors='raise')\n",
    "\n",
    "DelColumns = ['ID', 'Weight', 'CostCar', 'CoderegionCAR']\n",
    "data.drop(columns=DelColumns, inplace=True)\n",
    "print(\"data shape: \", data.shape)\n",
    "\n",
    "ReqDummy = ['DestAct', 'HouseType', 'Mothertongue', 'FamilSitu', 'OccupStat', 'SocioProfCat', 'Education', 'TripPurpose', 'TypeCommune', 'ClassifCodeLine', 'ResidChild', 'Region', 'ModeToSchool']\n",
    "\n",
    "dummydata = pd.DataFrame()\n",
    "for feat in ReqDummy:\n",
    "    if feat in data.columns:\n",
    "        dummydata[feat] = data[feat]\n",
    "    else:\n",
    "        print(f\"Column '{feat}' not found in data\")\n",
    "    \n",
    "    # Deleting the original column in the main dataframe\n",
    "    data.drop(feat, axis = 1, inplace = True)\n",
    "\n",
    "y = data['Choice']\n",
    "X = data.drop(columns=['Choice'])\n",
    "X_dummy = dummydata\n",
    "\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"X_dummy shape: \", X_dummy.shape)\n",
    "print(\"y \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f7c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data (ONLY X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "temp_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# create a new DataFrame with the scaled data\n",
    "X_scaled = pd.DataFrame(temp_scaled, columns=X.columns)\n",
    "print('X_scaled shape: ', X_scaled.shape)\n",
    "print('X_dummy shape: ', X_dummy.shape)\n",
    "\n",
    "# Checking that the dimensions are right and amount of NaN entries\n",
    "y = y.reset_index(drop=True)\n",
    "X_scaled = X_scaled.reset_index(drop=True)\n",
    "X_dummy = X_dummy.reset_index(drop=True)\n",
    "X_tot = pd.concat([X_scaled, X_dummy], axis=1)\n",
    "y_standard = y\n",
    "X_scaled_standard = X_scaled\n",
    "X_dummy_standard = X_dummy\n",
    "X_tot_standard = X_tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_inator(X, na_indicator = True):\n",
    "    # X is the input dataframe with all the columns that need to be split into dubby variables\n",
    "    # na_indicator is a boolean variable (optional function input)\n",
    "    # if na_indicator is False, NaN entries will lead to all False dummy variables\n",
    "    # if na_indicator is True, an extra dummy variable will be created for each feature, indicating (True/False) if there was a NaN entry\n",
    "    print('----- Generating the dummy variables')\n",
    "    DumbOutput = pd.DataFrame()\n",
    "    columns = X.columns\n",
    "    for feat in columns:\n",
    "        dummies = pd.get_dummies(X[feat], prefix=feat, dummy_na=na_indicator)\n",
    "        DumbOutput = pd.concat([DumbOutput, dummies], axis=1)\n",
    "        print(f\"fixed {feat} by adding {dummies.shape[1]} dummy variables.\")\n",
    "    print('-----')\n",
    "    return DumbOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17117893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert predictions from one-hot encoding to class labels\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Generate classification report with F1-score\n",
    "    report = classification_report(y_test_classes, y_pred_classes, digits=4)\n",
    "\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "def train_model(model, X_train, X_test, y_train, y_test, epochs, batch_size, results_show=False):\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    if results_show:\n",
    "        evaluate_model(model, X_test, y_test)\n",
    "\n",
    "    return history\n",
    "\n",
    "def create_model(X_train, X_test, y_train, y_test, results_show=False):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train.shape[1],) ),  # Input layer with 52 neurons\n",
    "        layers.Dense(64, activation='relu'),  # First hidden layer\n",
    "        layers.Dense(32, activation='relu'),  # Second hidden layer\n",
    "        layers.Dense(16, activation='relu'),  # Third hidden layer\n",
    "        layers.Dense(2, activation='softmax')  # Output layer with 2 neurons (classification)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    if results_show:\n",
    "        model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def plot_history(history):\n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba711ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(X, y, Tsize=0.2):\n",
    "    # Check class distribution before SMOTE\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(\"Before SMOTE:\", dict(zip(unique, counts)))\n",
    "\n",
    "    # Split the data into training and testing sets (use original y here)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=Tsize, random_state=RandomState, stratify=y)\n",
    "\n",
    "    # Apply SMOTE to integer labels\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    # Check class distribution after SMOTE\n",
    "    unique, counts = np.unique(y_train_resampled, return_counts=True)\n",
    "    print(\"After SMOTE:\", dict(zip(unique, counts)))\n",
    "\n",
    "    return X_train_resampled, y_train_resampled\n",
    "\n",
    "# Making the data split before imputation and/or augmentation\n",
    "def make_custom_split (X_scaled, X_dummy, y, valid_rows, random_state):\n",
    "    # Identify valid rows (no NaNs in either dataset)\n",
    "    #valid_rows = (~X_scaled.isna().any(axis=1)) & (~X_dummy.isna().any(axis=1))\n",
    "    \n",
    "    # Create clean versions\n",
    "    X_scaled_clean = X_scaled[valid_rows]\n",
    "    X_dummy_clean = X_dummy[valid_rows]\n",
    "    y_clean = y[valid_rows]\n",
    "    \n",
    "    # Train-test split using indices\n",
    "    X_indices = X_scaled_clean.index  # Save original indices\n",
    "    train_idx, test_idx = train_test_split(X_indices, random_state=random_state, test_size=0.2)\n",
    "    \n",
    "    # Create train/test splits\n",
    "    X_train_scaled = X_scaled.loc[train_idx]\n",
    "    X_train_dummy  = X_dummy.loc[train_idx]\n",
    "    y_train        = y.loc[train_idx]\n",
    "    # these train datapoints will not actually get used, because we want to generate the train data after imputation and augmentation...\n",
    "    \n",
    "    # the test datapoints are good and will be used\n",
    "    X_test_scaled  = X_scaled.loc[test_idx]\n",
    "    X_test_dummy   = X_dummy.loc[test_idx]\n",
    "    y_test         = y.loc[test_idx]\n",
    "    \n",
    "    # Update the original X_scaled and X_dummy to exclude the test rows\n",
    "    X_scaled = X_scaled.drop(index=test_idx)\n",
    "    X_dummy  = X_dummy.drop(index=test_idx)\n",
    "    y = y.drop(index = test_idx)\n",
    "\n",
    "    return X_test_scaled, X_test_dummy, y_test, X_scaled, X_dummy, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef52451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(Filltype, dataAugmentation, CatDealer, use_attitudes, X_dummy, X_scaled, y, seed, return_data=False):\n",
    "    if CatDealer:\n",
    "        print('Deleting rows with NaNs categorical features')\n",
    "        # Identify rows in X_dummy that contain NaN values\n",
    "        nan_mask = X_dummy.isna().any(axis=1)  # True for rows with any NaN\n",
    "        # Drop those rows in both X_dummy, X_scaled and y\n",
    "        X_dummy_cleaned = X_dummy[~nan_mask].reset_index(drop=True)\n",
    "        X_scaled_cleaned = X_scaled[~nan_mask].reset_index(drop=True)\n",
    "        y_cleaned = y[~nan_mask].reset_index(drop=True)\n",
    "        print('y shape: ', y_cleaned.shape)\n",
    "        print('X_scaled shape: ', X_scaled_cleaned.shape)\n",
    "        print('X_dummy shape: ', X_dummy_cleaned.shape)\n",
    "        X_WithDummies = dummy_inator(X_dummy_cleaned, False)\n",
    "\n",
    "        # Identify valid rows (no NaNs in either dataset)\n",
    "        valid_rows = (~X_scaled_cleaned.isna().any(axis=1)) & (~X_dummy_cleaned.isna().any(axis=1))\n",
    "        X_test_scaled, X_test_dummy, y_test, X_scaled, X_dummy, y = make_custom_split(X_scaled_cleaned, X_WithDummies, y_cleaned, valid_rows, seed)\n",
    "\n",
    "    else:\n",
    "        print(X_dummy)\n",
    "        X_dummy_cleaned = X_dummy\n",
    "        X_scaled_cleaned = X_scaled\n",
    "        y_cleaned = y\n",
    "        print('y shape: ', y_cleaned.shape)\n",
    "        print('X_scaled shape: ', X_scaled_cleaned.shape)\n",
    "        print('X_dummy shape: ', X_dummy_cleaned.shape)\n",
    "        X_WithDummies = dummy_inator(X_dummy_cleaned, True)\n",
    "\n",
    "        # Identify valid rows (no NaNs in either dataset)\n",
    "        valid_rows = (~X_scaled_cleaned.isna().any(axis=1)) & (~X_dummy_cleaned.isna().any(axis=1))\n",
    "        X_test_scaled, X_test_dummy, y_test, X_scaled, X_dummy, y = make_custom_split(X_scaled_cleaned, X_WithDummies, y_cleaned, valid_rows, seed)\n",
    "        \n",
    "\n",
    "    # Joining the Categorical and non Categorical features, the last column will be the choice one\n",
    "    data = pd.concat([X_scaled, X_dummy, y], axis=1)\n",
    "    data_test = pd.concat([X_test_scaled, X_test_dummy, y_test], axis=1)\n",
    "    # At this stage, data_test is ready and we'll do nothing more to it\n",
    "\n",
    "    print('data shape before Filling: ', data.shape)\n",
    "    data.to_csv(\"DataPreFilled.csv\", index=False)\n",
    "\n",
    "    match Filltype:\n",
    "        case 0:\n",
    "            # drop all rows with NaN entries\n",
    "            data = data.dropna()\n",
    "        case 1:\n",
    "            # Doing a super simple and stupid forward fill.\n",
    "            # also bfill is possible...\n",
    "            data = data.ffill()\n",
    "        case 2:\n",
    "            # SimpleImputer - most_frequent\n",
    "            imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "            data2 = pd.DataFrame(imp.fit_transform(data))\n",
    "            data2.columns = data.columns\n",
    "            data2.index = data.index\n",
    "            data = data2\n",
    "        case 3:\n",
    "            # This method is quite expensive computationally!\n",
    "            imputer = IterativeImputer(max_iter=15, random_state = 42, initial_strategy = 'mean')\n",
    "            data2 = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "            data = data2\n",
    "        case 4:\n",
    "            # SimpleImputer - mean\n",
    "            imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "            data2 = pd.DataFrame(imp.fit_transform(data))\n",
    "            data2.columns = data.columns\n",
    "            data2.index = data.index\n",
    "            data = data2\n",
    "        \n",
    "        # Attitude questions\n",
    "\n",
    "    if not use_attitudes:\n",
    "        DelColumns = []\n",
    "        DelColumns += [f'Envir{i:02d}' for i in range(1, 7)]\n",
    "        DelColumns += [f'Mobil{i:02d}' for i in range(1, 28)]\n",
    "        DelColumns += [f'ResidCh{i:02d}' for i in range(1, 8)]\n",
    "        DelColumns += [f'LifSty{i:02d}' for i in range(1, 15)]\n",
    "        data.drop(columns=[col for col in DelColumns if col in data.columns], inplace=True)\n",
    "        data_test.drop(columns=[col for col in DelColumns if col in data_test.columns], inplace=True)\n",
    "    \n",
    "\n",
    "    #extracting the last column (Choice)\n",
    "    # and converting to NUMPY ARRAYS!\n",
    "    y = data.iloc[:, -1].values\n",
    "    data.drop(data.columns[-1], axis=1, inplace = True) # remove the last colum (Choice)\n",
    "    X_tot = data.values\n",
    "\n",
    "    y_test = data_test.iloc[:, -1].values\n",
    "    data_test.drop(data_test.columns[-1], axis=1, inplace = True)\n",
    "    X_tot_test = data_test.values\n",
    "    \n",
    "    print('y shape: ', y.shape)\n",
    "    print('data shape: ', data.shape)\n",
    "    print('y_test shape: ', y_test.shape)\n",
    "    print('data_test shape: ', data_test.shape)\n",
    "        \n",
    "    # Augment and split the data\n",
    "    X_data = X_tot.astype(np.float32)\n",
    "    y_data = y.astype(int)\n",
    "    print(\"X_data shape: \", X_data.shape)\n",
    "    X_test = X_tot_test.astype(np.float32)\n",
    "    y_num_test = y_test.astype(int)\n",
    "\n",
    "    if dataAugmentation:\n",
    "        X_train, y_train_LOG = augment_data(X_data, y_data, Tsize=0.2)\n",
    "        print(\"X_train shape: \", X_train.shape)\n",
    "        y_train_NN = to_categorical(y_train_LOG, num_classes=2)\n",
    "        y_test_NN = to_categorical(y_num_test, num_classes=2)\n",
    "    else:\n",
    "        X_train = X_data\n",
    "        y_train_NN = to_categorical(y_data, num_classes=2)\n",
    "        y_test_NN = to_categorical(y_num_test, num_classes=2)\n",
    "\n",
    "    model = create_model(X_train, X_test, y_train_NN, y_test_NN, results_show=False)\n",
    "    # Train the model\n",
    "    print(X_train.shape, X_test.shape, y_train_NN.shape, y_test_NN.shape)\n",
    "    history = train_model(model, X_train, X_test, y_train_NN, y_test_NN, epochs=100, batch_size=32, results_show=False)\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
    "\n",
    "    if return_data:\n",
    "        return acc, prec, f1, cm, model, X_test, y_num_test, X_train, y_train_NN, y_test_NN, y_test\n",
    "    else:\n",
    "        return acc, prec, f1, cm\n",
    "\n",
    "# Run All 40 Configs\n",
    "results = []\n",
    "configs = list(product(range(5), [True, False], [0, 1], [True, False]))\n",
    "\n",
    "for i, (fill, aug, cat, att) in enumerate(configs):\n",
    "    print(f\"\\nRunning config {i+1}/40 --> Filltype={fill}, Aug={aug}, CatDealer={cat}, Attitudes={att}\")\n",
    "    acc, prec, f1, cm = run_pipeline(fill, aug, cat, att, X_dummy_standard, X_scaled_standard, y_standard, random_state=42)\n",
    "    results.append({\n",
    "        'Config_ID': i+1,\n",
    "        'Filltype': fill,\n",
    "        'DataAug': aug,\n",
    "        'CatDealer': cat,\n",
    "        'AttitudesUsed': att,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'F1_Score': f1,\n",
    "        'Confusion_Matrix': cm\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"NN_Comparison_Results.csv\", index=False)\n",
    "print(\"\\n All results saved to 'NN_Comparison_Results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99835375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CONFIG\n",
    "N_SEEDS = 5\n",
    "SEED_LIST = [random.randint(0, 99999) for _ in range(N_SEEDS)] \n",
    "TestSize = 0.2\n",
    "\n",
    "# Save seeds for reproducibility\n",
    "pd.DataFrame({'Seed': SEED_LIST}).to_csv(\"Used_Seeds.csv\", index=False)\n",
    "\n",
    "# RESULTS STRUCTURE \n",
    "configs = list(product(range(5), [True, False], [0, 1], [True, False]))  # 40 combinations\n",
    "all_results = []\n",
    "\n",
    "# RUNNING LOOP\n",
    "for config_id, (Filltype, dataAug, CatDealer, use_attitudes) in enumerate(configs, start=1):\n",
    "    acc_list = []\n",
    "    prec_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    print(f\"\\n Config {config_id}/40 - Fill={Filltype}, Aug={dataAug}, Cat={CatDealer}, Att={use_attitudes}\")\n",
    "\n",
    "    for seed in SEED_LIST:\n",
    "\n",
    "        acc, prec, f1, cm = run_pipeline(fill, aug, cat, att, X_dummy_standard, X_scaled_standard, y_standard, seed)\n",
    "\n",
    "        acc_list.append(acc)\n",
    "        prec_list.append(prec)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    result_row = {\n",
    "        'Config_ID': config_id,\n",
    "        'Filltype': Filltype,\n",
    "        'DataAug': dataAug,\n",
    "        'CatDealer': CatDealer,\n",
    "        'AttitudesUsed': use_attitudes\n",
    "    }\n",
    "\n",
    "    for i in range(N_SEEDS):\n",
    "        result_row[f'Accuracy_{i+1}'] = acc_list[i]\n",
    "        result_row[f'Precision_{i+1}'] = prec_list[i]\n",
    "        result_row[f'F1_Score_{i+1}'] = f1_list[i]\n",
    "\n",
    "    result_row['Accuracy_Mean'] = np.mean(acc_list)\n",
    "    result_row['Precision_Mean'] = np.mean(prec_list)\n",
    "    result_row['F1_Score_Mean'] = np.mean(f1_list)\n",
    "\n",
    "    all_results.append(result_row)\n",
    "\n",
    "df_results = pd.DataFrame(all_results)\n",
    "df_results.to_excel(\"NN_Comparison_Results_MultiSeed.xlsx\", index=False)\n",
    "print(\"All results saved to 'NN_Comparison_Results_MultiSeed.xlsx'\")\n",
    "print(\"Random seeds saved to 'Used_Seeds.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the results\n",
    "df = pd.read_excel(\"NN_Comparison_Results_MultiSeedF.xlsx\")\n",
    "df.replace(',', '.', regex=True, inplace=True)\n",
    "\n",
    "# Ensure numeric types\n",
    "df['Precision_Mean'] = pd.to_numeric(df['Precision_Mean'], errors='coerce')\n",
    "df['F1_Score_Mean'] = pd.to_numeric(df['F1_Score_Mean'], errors='coerce')\n",
    "df['Accuracy_Mean'] = pd.to_numeric(df['Accuracy_Mean'], errors='coerce')\n",
    "\n",
    "# Filter for high precision average > 0.925\n",
    "high_precision_df = df[df['Precision_Mean'] > 0.925].copy()\n",
    "\n",
    "# Identify the best config based on F1 Score Mean\n",
    "best_config_idx = high_precision_df['F1_Score_Mean'].idxmax()\n",
    "best_config = high_precision_df.loc[best_config_idx]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.scatter(\n",
    "    high_precision_df['Accuracy_Mean'],\n",
    "    high_precision_df['F1_Score_Mean'],\n",
    "    c='royalblue',\n",
    "    s=80,\n",
    "    edgecolor='black',\n",
    "    label='High-Precision Configs (Precision > 0.925)'\n",
    ")\n",
    "\n",
    "# Labels for not overlapping\n",
    "label_styles = {\n",
    "    8: {'xytext': (25, 10), 'ha': 'left'},\n",
    "    32: {'xytext': (-30, -10), 'ha': 'right'},\n",
    "    22: {'xytext': (-20, 10), 'ha': 'right'},\n",
    "    40: {'xytext': (5, 25), 'ha': 'left'},\n",
    "    23: {'xytext': (5, 25), 'ha': 'left'},\n",
    "}\n",
    "\n",
    "# Annotate each config with ID (except best)\n",
    "for _, row in high_precision_df.iterrows():\n",
    "    cfg_id = int(row['Config_ID'])\n",
    "    if cfg_id != int(best_config['Config_ID']):\n",
    "        style = label_styles.get(cfg_id, {'xytext': (10, 10), 'ha': 'left'})\n",
    "        plt.annotate(\n",
    "            f\"ID {cfg_id}\",\n",
    "            (row['Accuracy_Mean'], row['F1_Score_Mean']),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=style['xytext'],\n",
    "            ha=style['ha'],\n",
    "            fontsize=9,\n",
    "            arrowprops=dict(\n",
    "                arrowstyle='->',\n",
    "                color='gray',\n",
    "                connectionstyle='arc3,rad=0.2'\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Highlight best config\n",
    "plt.scatter(\n",
    "    best_config['Accuracy_Mean'],\n",
    "    best_config['F1_Score_Mean'],\n",
    "    c='darkorange',\n",
    "    s=120,\n",
    "    edgecolor='black',\n",
    "    label=f\"Best Config (ID {int(best_config['Config_ID'])})\",\n",
    "    marker='*',\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "# Annotate best config\n",
    "plt.annotate(\n",
    "    f\"Best Config\\nID: {int(best_config['Config_ID'])}\\nF1: {best_config['F1_Score_Mean']:.3f}\",\n",
    "    (best_config['Accuracy_Mean'], best_config['F1_Score_Mean']),\n",
    "    textcoords=\"offset points\",\n",
    "    xytext=(10, -25),\n",
    "    ha='left',\n",
    "    fontsize=10,\n",
    "    arrowprops=dict(\n",
    "        arrowstyle='->',\n",
    "        color='gray',\n",
    "        connectionstyle='arc3,rad=-0.2'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Mean Accuracy', fontsize=13)\n",
    "plt.ylabel('Mean F1 Score', fontsize=13)\n",
    "#plt.title('Best Configurations with Precision_Mean > 0.925', fontsize=15)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FIXED CONFIG ID 23 \n",
    "Filltype = 2\n",
    "dataAug = False\n",
    "CatDealer = 1\n",
    "AttitudesUsed = True\n",
    "TestSize = 0.2\n",
    "SEEDS = [random.randint(0, 100000) for _ in range(5)]\n",
    "\n",
    "# Define NN Architectures \n",
    "architectures = [\n",
    "    {'name': '1.1',      'arch': [32],              'act': 'relu',    'final_act': 'softmax', 'batch': 32},\n",
    "    {'name': '1.2',      'arch': [32],              'act': 'relu',    'final_act': 'softmax', 'batch': 44},\n",
    "    {'name': '1.3',      'arch': [32],              'act': 'relu',    'final_act': 'softmax', 'batch': 64},\n",
    "    {'name': '2.1', 'arch': [64, 32],          'act': 'relu',    'final_act': 'softmax', 'batch': 32},\n",
    "    {'name': '2.2', 'arch': [64, 32],          'act': 'relu',    'final_act': 'softmax', 'batch': 44},\n",
    "    {'name': '2.3', 'arch': [64, 32],          'act': 'relu',    'final_act': 'softmax', 'batch': 64},\n",
    "    {'name': '3.1', 'arch': [64, 32, 16],      'act': 'relu',    'final_act': 'softmax', 'batch': 32},\n",
    "    {'name': '3.2 - Baseline', 'arch': [64, 32, 16],      'act': 'relu',    'final_act': 'softmax', 'batch': 44},\n",
    "    {'name': '3.3', 'arch': [64, 32, 16],      'act': 'relu',    'final_act': 'softmax', 'batch': 64},\n",
    "    {'name': '4.1',      'arch': [128, 64, 32, 16],      'act': 'relu',    'final_act': 'softmax', 'batch': 32},\n",
    "    {'name': '4.2',      'arch': [128, 64, 32, 16],      'act': 'relu',    'final_act': 'softmax', 'batch': 44},\n",
    "    {'name': '4.3',      'arch': [128, 64, 32, 16],      'act': 'relu',    'final_act': 'softmax', 'batch': 64},\n",
    "    {'name': '5.1',   'arch': [64, 32, 16, 32, 64, 32, 16],      'act': 'relu', 'final_act': 'softmax', 'batch': 32},\n",
    "    {'name': '5.2',   'arch': [64, 32, 16, 32, 64, 32, 16],      'act': 'relu', 'final_act': 'softmax', 'batch': 44},\n",
    "    {'name': '5.3',   'arch': [64, 32, 16, 32, 64, 32, 16],      'act': 'relu', 'final_act': 'softmax', 'batch': 64},\n",
    "    {'name': '6.1',   'arch': [128, 64, 32, 16, 32, 64, 128, 64, 32, 16],      'act': 'relu', 'final_act': 'softmax', 'batch': 32},\n",
    "    {'name': '6.2',   'arch': [128, 64, 32, 16, 32, 64, 128, 64, 32, 16],      'act': 'relu', 'final_act': 'softmax', 'batch': 44},\n",
    "    {'name': '6.3',   'arch': [128, 64, 32, 16, 32, 64, 128, 64, 32, 16],      'act': 'relu', 'final_act': 'softmax', 'batch': 64}\n",
    "]\n",
    "\n",
    "\n",
    "# Model builder\n",
    "def build_model(arch, input_shape, activation, final_activation):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Input(shape=(input_shape,)))\n",
    "    for units in arch:\n",
    "        model.add(layers.Dense(units, activation=activation))\n",
    "    model.add(layers.Dense(2, activation=final_activation))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Store Results\n",
    "results = []\n",
    "\n",
    "for arch_def in architectures:\n",
    "    acc_list, prec_list, f1_list = [], [], []\n",
    "    print(f\"\\n Testing {arch_def['name']} ...\")\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        RandomState = seed\n",
    "        # Get fresh data each run\n",
    "        _, _, _, _, _, X_test, _, X_train, y_train_NN, y_test_NN, y_test = run_pipeline(\n",
    "            Filltype, dataAug, CatDealer, AttitudesUsed, X_dummy_standard, X_scaled_standard, y_standard, RandomState, return_data=True\n",
    "        )\n",
    "\n",
    "        # Build model\n",
    "        model = build_model(\n",
    "            arch=arch_def['arch'],\n",
    "            input_shape=X_train.shape[1],\n",
    "            activation=arch_def['act'],\n",
    "            final_activation=arch_def['final_act']\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        train_model(\n",
    "            model,\n",
    "            X_train,\n",
    "            X_test,\n",
    "            y_train_NN,\n",
    "            y_test_NN,\n",
    "            epochs=100,\n",
    "            batch_size=arch_def['batch'],\n",
    "            results_show=True\n",
    "        )\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred).tolist()\n",
    "\n",
    "        acc_list.append(acc)\n",
    "        prec_list.append(prec)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    results.append({\n",
    "        'Architecture': arch_def['name'],\n",
    "        'Hidden_Layers': str(arch_def['arch']),\n",
    "        'Activation': arch_def['act'],\n",
    "        'BatchSize': arch_def['batch'],\n",
    "        'Accuracy_Mean': np.mean(acc_list),\n",
    "        'Precision_Mean': np.mean(prec_list),\n",
    "        'F1_Score_Mean': np.mean(f1_list),\n",
    "        'Acc_Seeds': acc_list,\n",
    "        'Prec_Seeds': prec_list,\n",
    "        'F1_Seeds': f1_list,\n",
    "        'Seeds': SEEDS\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(\"NN_Architecture_Search_Final.xlsx\", index=False)\n",
    "print(\"\\n Results saved to 'NN_Architecture_Search_Final.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a309261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the final model\n",
    "\n",
    "# FIXED CONFIG ID 23 \n",
    "Filltype = 2\n",
    "dataAug = False\n",
    "CatDealer = 1\n",
    "AttitudesUsed = True\n",
    "TestSize = 0.2\n",
    "seed = 12345  # Fixed seed for reproducibility\n",
    "\n",
    "_, _, _, _, _, X_test, _, X_train, y_train_NN, y_test_NN, y_test = run_pipeline(\n",
    "Filltype, dataAug, CatDealer, AttitudesUsed, X_dummy_standard, X_scaled_standard, y_standard, RandomState, return_data=True\n",
    ")\n",
    "\n",
    "# Define NN Architecture (final model - 3.2)\n",
    "\n",
    "final_model = build_model(\n",
    "    arch=[64, 32, 16],\n",
    "    input_shape=X_train.shape[1],\n",
    "    activation='relu',\n",
    "    final_activation='softmax'\n",
    ")\n",
    "\n",
    "history = train_model(\n",
    "            final_model,\n",
    "            X_train,\n",
    "            X_test,\n",
    "            y_train_NN,\n",
    "            y_test_NN,\n",
    "            epochs=100,\n",
    "            batch_size=44,\n",
    "            results_show=True\n",
    "        )\n",
    "\n",
    "final_model.save(\"Final_Model.keras\")\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred).tolist()\n",
    "\n",
    "print(\"Final Model Evaluation:\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c62f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Sensitivity Analysis\n",
    "\n",
    "# Load full dataset for ground truth computation\n",
    "raw_data = pd.read_csv(\"ModeChoiceOptima.txt\", sep=\"\\t\", header=None)\n",
    "featureNames = raw_data.iloc[0]\n",
    "raw_data.columns = featureNames\n",
    "raw_data = raw_data[1:]\n",
    "\n",
    "nan_mask = X_dummy_standard.isna().any(axis=1)  # True for rows with any NaN\n",
    "# Drop those rows in both X_dummy, X_scaled and y\n",
    "X_dummy_cleaned = X_dummy_standard[~nan_mask].reset_index(drop=True)\n",
    "X_scaled_cleaned = X_scaled_standard[~nan_mask].reset_index(drop=True)\n",
    "y_cleaned = y[~nan_mask].reset_index(drop=True)\n",
    "\n",
    "X_WithDummies = dummy_inator(X_dummy_cleaned, False)\n",
    "X_input = pd.concat([X_scaled_cleaned, X_WithDummies], axis=1)\n",
    "\n",
    "X_input = X_input.dropna().astype(int)\n",
    "\n",
    "pt_count = np.sum(y_cleaned == 0)\n",
    "priv_count = np.sum(y_cleaned == 1)\n",
    "total_valid = pt_count + priv_count\n",
    "true_ground_pct = pt_count / total_valid * 100\n",
    "print(f\"Ground Truth from dataset: {pt_count}/{total_valid} → {true_ground_pct:.2f}% use PT\")\n",
    "\n",
    "\n",
    "final_model = load_model(\"Final_Model.keras\")\n",
    "\n",
    "\n",
    "y_pred_base = np.argmax(final_model.predict(X_input, verbose=0), axis=1)\n",
    "pt_pred_base_pct = np.sum(y_pred_base == 0) / len(y_pred_base) * 100\n",
    "print(f\"Model Baseline Prediction: {pt_pred_base_pct:.2f}% use PT\")\n",
    "\n",
    "X_notscaled = data.drop(columns=['Choice'])\n",
    "X_notscaled = X_notscaled.reset_index(drop=True)\n",
    "X_notscaled_cleaned = X_notscaled[~nan_mask].reset_index(drop=True)\n",
    "\n",
    "X_tovary = pd.concat([X_notscaled_cleaned, X_WithDummies], axis=1)\n",
    "X_tovary = X_tovary.dropna().astype(int)\n",
    "\n",
    "X_notscaled_tovary = X_tovary.iloc[:, :99]\n",
    "X_notscaled_dummies = X_tovary.iloc[:, 99:]\n",
    "\n",
    "# Features to vary (individually)\n",
    "features_to_vary = [\"NbTransf\", \"TimePT\", \"WalkingTimePT\", \"WaitingTimePT\", \"CostPT\"]\n",
    "variation_percentages = list(range(-50, 51, 1))  # 1% steps\n",
    "sensitivity_results = {}\n",
    "\n",
    "# Individual feature variation\n",
    "for feat in features_to_vary:\n",
    "    if feat not in X_notscaled_cleaned.columns:\n",
    "        print(f\" Skipping {feat}, not found.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Varying {feat}\")\n",
    "    original = X_notscaled_cleaned[feat].copy()\n",
    "    results = []\n",
    "\n",
    "    for pct in variation_percentages:\n",
    "        factor = 1 + pct / 100\n",
    "        X_mod = X_notscaled_cleaned.copy()\n",
    "        X_mod[feat] = original * factor\n",
    "\n",
    "        temp_scaled_mod = scaler.transform(X_mod)\n",
    "        X_mod_scaled = pd.DataFrame(temp_scaled_mod, columns=X_mod.columns)\n",
    "        X_mod_input = pd.concat([X_mod_scaled, X_WithDummies], axis=1)\n",
    "        X_mod_input = X_mod_input.dropna().astype(int)\n",
    "\n",
    "        y_pred = np.argmax(final_model.predict(X_mod_input, verbose=0), axis=1)\n",
    "        pct_pt_users = np.sum(y_pred == 0) / len(y_pred) * 100  \n",
    "        results.append(pct_pt_users)\n",
    "\n",
    "    sensitivity_results[feat] = results\n",
    "\n",
    "# Combined improvement scenario\n",
    "combined_results = []\n",
    "good_directions = {\n",
    "    \"NbTransf\": 1,\n",
    "    \"TimePT\": 1,\n",
    "    \"WalkingTimePT\": 1,\n",
    "    \"WaitingTimePT\": 1,\n",
    "    \"CostPT\": 1\n",
    "}\n",
    "\n",
    "for pct in variation_percentages:\n",
    "    X_comb = X_notscaled_cleaned.copy()\n",
    "    for feat, direction in good_directions.items():\n",
    "        if feat in X_comb.columns:\n",
    "            X_comb[feat] *= (1 + direction * pct / 100)\n",
    "\n",
    "    temp_scaled_comb = scaler.transform(X_comb)\n",
    "    X_comb_scaled = pd.DataFrame(temp_scaled_comb, columns=X_comb.columns)\n",
    "    X_comb_input = pd.concat([X_comb_scaled, X_WithDummies], axis=1)\n",
    "    X_comb_input = X_comb_input.dropna().astype(int)\n",
    "  \n",
    "    y_pred = np.argmax(final_model.predict(X_comb_input, verbose=0), axis=1)\n",
    "    pct_pt_users = np.sum(y_pred == 0) / len(y_pred) * 100\n",
    "    combined_results.append(pct_pt_users)\n",
    "\n",
    "# Plotting\n",
    "all_features = list(sensitivity_results.keys()) + [\"Combined\"]\n",
    "ncols = 3\n",
    "nrows = (len(all_features) + ncols - 1) // ncols\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(16, 4 * nrows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feat in enumerate(all_features):\n",
    "    ax = axes[idx]\n",
    "    values = sensitivity_results[feat] if feat != \"Combined\" else combined_results\n",
    "\n",
    "    ax.plot(variation_percentages, values, marker='.', linestyle='-', color='tab:blue', label='Predicted % PT')\n",
    "    ax.axhline(y=true_ground_pct, linestyle='--', color='gray', label='True % from Dataset')\n",
    "    ax.axhline(y=pt_pred_base_pct, linestyle=':', color='green', label='Model Baseline %')\n",
    "    ax.set_title(f\"Effect of Varying {feat}\", fontsize=13)\n",
    "    ax.set_xlabel(\"Percentage Change\", fontsize=11)\n",
    "    ax.set_ylabel(\"% Predicted PT Users\", fontsize=11)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Set custom x-ticks every 5%\n",
    "    ax.set_xticks([i for i in variation_percentages if i % 5 == 0])\n",
    "\n",
    "    # Zoom in on the relevant Y range\n",
    "    y_min = min(values + [true_ground_pct, pt_pred_base_pct])\n",
    "    y_max = max(values + [true_ground_pct, pt_pred_base_pct])\n",
    "    padding = max(0.3, (y_max - y_min) * 0.2)\n",
    "    ax.set_ylim([y_min - padding, y_max + padding])\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "# Remove unused subplots\n",
    "for i in range(len(all_features), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional Sensitivity Analysis\n",
    "region_columns = [col for col in X_input.columns if col.startswith('Region_')]\n",
    "pt_percentage_per_region = {}\n",
    "\n",
    "for col in region_columns:\n",
    "    # Get the indexes where this region column is 1\n",
    "    region_idx = X_input[X_input[col] == 1].index\n",
    "    region_y = y_cleaned.loc[region_idx]\n",
    "\n",
    "    pt_count = np.sum(region_y == 0)\n",
    "    priv_count = np.sum(region_y == 1)\n",
    "    total_valid = pt_count + priv_count\n",
    "\n",
    "    if total_valid == 0:\n",
    "        continue\n",
    "\n",
    "    pt_pct = pt_count / total_valid * 100\n",
    "    pt_percentage_per_region[col] = pt_pct\n",
    "\n",
    "    print(f\"{col}: {pt_count}/{total_valid} → {pt_pct:.2f}% use PT\")\n",
    "\n",
    "# Load model\n",
    "final_model = load_model(\"Final_Model.keras\")\n",
    "\n",
    "# Define settings\n",
    "features_to_vary = [\"NbTransf\", \"TimePT\", \"WalkingTimePT\", \"WaitingTimePT\", \"CostPT\"]\n",
    "variation_percentages = list(range(-50, 51, 1))\n",
    "region_columns = [col for col in X_input.columns if col.startswith(\"Region_\")]\n",
    "\n",
    "X_notscaled_cleaned = X_notscaled_cleaned.copy()\n",
    "\n",
    "# Store all region-specific data\n",
    "region_sensitivity = {}\n",
    "\n",
    "for region_col in region_columns:\n",
    "    print(f\"Processing {region_col}\")\n",
    "    \n",
    "    # Get data and labels for this region\n",
    "    region_idx = X_input[X_input[region_col] == 1].index\n",
    "    region_data = X_input.loc[region_idx]\n",
    "    region_y = y_cleaned.loc[region_idx]\n",
    "\n",
    "    X_region_notscaled_idx = X_tovary[X_tovary[region_col] == 1].index\n",
    "    X_region_notscaled = X_notscaled_cleaned.loc[X_region_notscaled_idx]\n",
    "    region_dummies = X_notscaled_dummies.loc[X_region_notscaled_idx]\n",
    "    \n",
    "    if len(region_data) == 0:\n",
    "        continue\n",
    "\n",
    "    # Ground truth % PT\n",
    "    pt_count = np.sum(region_y == 0)\n",
    "    priv_count = np.sum(region_y == 1)\n",
    "    total_valid = pt_count + priv_count\n",
    "    if total_valid == 0:\n",
    "        continue\n",
    "    true_ground_pct = pt_count / total_valid * 100\n",
    "\n",
    "    # Model baseline prediction\n",
    "    y_pred_base = np.argmax(final_model.predict(region_data, verbose=0), axis=1)\n",
    "    pt_pred_base_pct = np.sum(y_pred_base == 0) / len(y_pred_base) * 100\n",
    "\n",
    "    region_result = {}\n",
    "\n",
    "    for feat in features_to_vary:\n",
    "        if feat not in X_region_notscaled.columns:\n",
    "            print(f\" Skipping {feat}, not found.\")\n",
    "            continue\n",
    "\n",
    "        original = X_region_notscaled[feat].copy()\n",
    "        result = []\n",
    "\n",
    "        for pct in variation_percentages:\n",
    "            factor = 1 + pct / 100\n",
    "            X_mod = X_region_notscaled.copy()\n",
    "            X_mod[feat] = original * factor\n",
    "\n",
    "            temp_scaled_regions = scaler.transform(X_mod)\n",
    "            X_regions_scaled = pd.DataFrame(temp_scaled_regions, columns=X_mod.columns)\n",
    "            X_regions_scaled = X_regions_scaled.reset_index(drop=True)\n",
    "            region_dummies = region_dummies.reset_index(drop=True)\n",
    "            X_regions_input = pd.concat([X_regions_scaled, region_dummies], axis=1)\n",
    "            X_regions_input = X_regions_input.dropna().astype(int)\n",
    "\n",
    "            y_pred = np.argmax(final_model.predict(X_regions_input, verbose=0), axis=1)\n",
    "            pct_pt_users = np.sum(y_pred == 0) / len(y_pred) * 100\n",
    "            result.append(pct_pt_users)\n",
    "\n",
    "        region_result[feat] = result\n",
    "\n",
    "    # Save everything\n",
    "    region_sensitivity[region_col] = {\n",
    "        \"sensitivity\": region_result,\n",
    "        \"true_pct\": true_ground_pct,\n",
    "        \"baseline_pct\": pt_pred_base_pct\n",
    "    }\n",
    "\n",
    "# Plotting\n",
    "ncols = 2\n",
    "nrows = (len(region_sensitivity) + ncols - 1) // ncols\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(16, 4 * nrows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (region, result) in enumerate(region_sensitivity.items()):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    for feat in features_to_vary:\n",
    "        if feat in result[\"sensitivity\"]:\n",
    "            ax.plot(variation_percentages, result[\"sensitivity\"][feat], label=feat)\n",
    "\n",
    "    ax.axhline(y=result[\"true_pct\"], linestyle='--', color='gray', label='True % PT')\n",
    "    ax.axhline(y=result[\"baseline_pct\"], linestyle=':', color='green', label='Model Baseline %')\n",
    "    ax.set_title(f\"{region.replace('_', ' ')}\", fontsize=13)\n",
    "    ax.set_xlabel(\"Percentage Change\", fontsize=11)\n",
    "    ax.set_ylabel(\"% Predicted PT Users\", fontsize=11)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.set_xticks([i for i in variation_percentages if i % 10 == 0])\n",
    "    ax.legend()\n",
    "\n",
    "# Remove unused subplots\n",
    "for i in range(len(region_sensitivity), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "fig.suptitle(\"Regional Sensitivity Analysis: % Predicted PT Users vs Feature Variation\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f21c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticket Sensitivity Analysis\n",
    "\n",
    "# Define tickets and their corresponding scaled values\n",
    "ticket_info = {\n",
    "    'HalfFareST': -1,\n",
    "    'LineRelST': -3,\n",
    "    'GenAbST': -3,\n",
    "    'AreaRelST': -3,\n",
    "    'OtherST': -4\n",
    "}\n",
    "# Tickets to evaluate\n",
    "ticket_cols = list(ticket_info.keys())\n",
    "all_cols = ['Baseline'] + ticket_cols\n",
    "\n",
    "\n",
    "region_columns = [col for col in X_input.columns if col.startswith(\"Region_\")]\n",
    "\n",
    "# Baseline prediction (global)\n",
    "y_pred_base_global = np.argmax(final_model.predict(X_input, verbose=0), axis=1)\n",
    "pt_pct_base_global = np.sum(y_pred_base_global == 0) / len(y_pred_base_global) * 100\n",
    "\n",
    "# Store all results\n",
    "ticket_results = {}\n",
    "ticket_colors = {\n",
    "    'Baseline': 'tab:blue',\n",
    "    'HalfFareST': 'tab:orange',\n",
    "    'LineRelST': 'tab:green',\n",
    "    'GenAbST': 'tab:red',\n",
    "    'AreaRelST': 'tab:purple',\n",
    "    'OtherST': 'tab:brown'\n",
    "}\n",
    "# All regions + global\n",
    "regions_to_plot = ['GLOBAL'] + list(region_columns)\n",
    "region_labels = [r.replace('_', ' ') for r in regions_to_plot]\n",
    "\n",
    "# Collect values per region\n",
    "data_matrix = []\n",
    "\n",
    "for region in regions_to_plot:\n",
    "    region_values = []\n",
    "\n",
    "    # Baseline first\n",
    "    if region == 'GLOBAL':\n",
    "        baseline = pt_pct_base_global\n",
    "    else:\n",
    "        # Use any ticket's baseline since it's the same across all\n",
    "        sample_ticket = next(iter(ticket_results))\n",
    "        baseline = ticket_results[sample_ticket]['regional'][region]['Before']\n",
    "\n",
    "    region_values.append(baseline)\n",
    "\n",
    "    # Then each ticket's effect\n",
    "    for ticket in ticket_cols:\n",
    "        if region == 'GLOBAL':\n",
    "            pt_pct = ticket_results[ticket]['global_after']\n",
    "        else:\n",
    "            pt_pct = ticket_results[ticket]['regional'].get(region, {}).get('After', np.nan)\n",
    "        region_values.append(pt_pct)\n",
    "\n",
    "    data_matrix.append(region_values)\n",
    "\n",
    "data_matrix = np.array(data_matrix)  \n",
    "\n",
    "# Plotting\n",
    "n_regions = len(regions_to_plot)\n",
    "n_bars = len(all_cols)\n",
    "x = np.arange(n_regions)\n",
    "bar_width = 0.12\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "for i, label in enumerate(all_cols):\n",
    "    offset = (i - n_bars / 2) * bar_width + bar_width / 2\n",
    "    ax.bar(x + offset, data_matrix[:, i], width=bar_width, label=label, color=ticket_colors[label])\n",
    "\n",
    "ax.set_ylabel('% Predicted PT Users')\n",
    "ax.set_title('Impact of Season Tickets on Public Transport Usage per Region')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(region_labels, rotation=45)\n",
    "ax.legend(title='Scenario')\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Season Tickets per Region\n",
    "\n",
    "ticket_cols = ['HalfFareST', 'LineRelST', 'GenAbST', 'AreaRelST', 'OtherST']\n",
    "ticket_colors = {\n",
    "    'HalfFareST': 'tab:orange',\n",
    "    'LineRelST': 'tab:green',\n",
    "    'GenAbST': 'tab:red',\n",
    "    'AreaRelST': 'tab:purple',\n",
    "    'OtherST': 'tab:brown'\n",
    "}\n",
    "region_columns = [col for col in X_input.columns if col.startswith(\"Region_\")]\n",
    "\n",
    "# List of regions + global\n",
    "regions_to_plot = ['GLOBAL'] + region_columns\n",
    "region_labels = [r.replace('_', ' ') for r in regions_to_plot]\n",
    "\n",
    "# Data matrix: rows = regions, columns = ticket types\n",
    "data_matrix = []\n",
    "\n",
    "for region in regions_to_plot:\n",
    "    if region == 'GLOBAL':\n",
    "        region_data = X_input\n",
    "    else:\n",
    "        region_data = X_input[X_input[region] == 1]\n",
    "\n",
    "    region_row = []\n",
    "    for ticket in ticket_cols:\n",
    "        if ticket in region_data.columns:\n",
    "            count_with_ticket = (region_data[ticket] != 0).sum()\n",
    "            pct_with_ticket = count_with_ticket / len(region_data) * 100 if len(region_data) > 0 else 0\n",
    "        else:\n",
    "            pct_with_ticket = np.nan\n",
    "        region_row.append(pct_with_ticket)\n",
    "\n",
    "    data_matrix.append(region_row)\n",
    "\n",
    "data_matrix = np.array(data_matrix)\n",
    "\n",
    "# Plotting\n",
    "n_regions = len(regions_to_plot)\n",
    "n_tickets = len(ticket_cols)\n",
    "x = np.arange(n_regions)\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "for i, ticket in enumerate(ticket_cols):\n",
    "    offset = (i - n_tickets / 2) * bar_width + bar_width / 2\n",
    "    ax.bar(\n",
    "        x + offset,\n",
    "        data_matrix[:, i],\n",
    "        width=bar_width,\n",
    "        label=ticket,\n",
    "        color=ticket_colors[ticket]\n",
    "    )\n",
    "\n",
    "ax.set_ylabel('% of Population with Season Ticket')\n",
    "ax.set_title('Original Distribution of Season Tickets per Region')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(region_labels, rotation=45)\n",
    "ax.legend(title='Ticket Type')\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CostCarCHF Sensitivity Analysis\n",
    "\n",
    "# Load model\n",
    "final_model = load_model(\"Final_Model.keras\")\n",
    "\n",
    "# Feature to vary\n",
    "feature_to_vary = \"CostCarCHF\"\n",
    "variation_percentages = list(range(-100, 101, 1))  # from -100% to +100%\n",
    "\n",
    "# Baseline prediction\n",
    "y_pred_base = np.argmax(final_model.predict(X_input, verbose=0), axis=1)\n",
    "pt_pred_base_pct = np.sum(y_pred_base == 0) / len(y_pred_base) * 100\n",
    "print(f\"Model Baseline Prediction: {pt_pred_base_pct:.2f}% use PT\")\n",
    "\n",
    "# Ground truth\n",
    "pt_count = np.sum(y_cleaned == 0)\n",
    "priv_count = np.sum(y_cleaned == 1)\n",
    "total_valid = pt_count + priv_count\n",
    "true_ground_pct = pt_count / total_valid * 100\n",
    "print(f\"Ground Truth from dataset: {pt_count}/{total_valid} → {true_ground_pct:.2f}% use PT\")\n",
    "\n",
    "# Sensitivity analysis for CostCarCHF\n",
    "print(f\"\\n Varying {feature_to_vary}\")\n",
    "original = X_notscaled_cleaned[feature_to_vary].copy()\n",
    "pt_pct_results = []\n",
    "\n",
    "for pct in variation_percentages:\n",
    "    factor = 1 + pct / 100\n",
    "    X_mod = X_notscaled_cleaned.copy()\n",
    "    X_mod[feature_to_vary] = original * factor\n",
    "\n",
    "    temp_scaled_mod = scaler.transform(X_mod)\n",
    "    X_mod_scaled = pd.DataFrame(temp_scaled_mod, columns=X_mod.columns)\n",
    "    X_mod_input = pd.concat([X_mod_scaled, X_WithDummies], axis=1)\n",
    "    X_mod_input = X_mod_input.dropna().astype(int)\n",
    "    \n",
    "    y_pred = np.argmax(final_model.predict(X_mod_input, verbose=0), axis=1)\n",
    "    pct_pt_users = np.sum(y_pred == 0) / len(y_pred) * 100\n",
    "    pt_pct_results.append(pct_pt_users)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(variation_percentages, pt_pct_results, marker='o', linestyle='-', color='tab:blue', label='Predicted % PT')\n",
    "plt.axhline(y=true_ground_pct, linestyle='--', color='gray', label='True % from Dataset')\n",
    "plt.axhline(y=pt_pred_base_pct, linestyle=':', color='green', label='Model Baseline %')\n",
    "plt.title(\"Effect of Varying CostCarCHF on PT Usage\")\n",
    "plt.xlabel(\"Percentage Change in CostCarCHF\")\n",
    "plt.ylabel(\"% Predicted PT Users\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.xticks([i for i in variation_percentages if i % 5 == 0])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
